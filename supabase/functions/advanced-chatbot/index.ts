import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.50.0'
import { corsHeaders } from '../_shared/cors.ts'

const supabase = createClient(
  Deno.env.get('SUPABASE_URL') ?? '',
  Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? ''
)

const openAIApiKey = Deno.env.get('OPENAI_API_KEY')

interface ConversationMemory {
  userProfile: {
    preferredName?: string;
    deviceBrand?: string;
    previousIssues?: string[];
    communicationStyle: 'formal' | 'casual' | 'technical';
    urgencyLevel: 'low' | 'medium' | 'high';
    satisfactionHistory: number[];
  };
  conversationContext: {
    currentIssue?: string;
    diagnosisStage: string;
    collectedSymptoms: string[];
    suggestedSolutions: string[];
    nearbyRepairers: any[];
  };
  emotionalJourney: {
    initialMood: string;
    currentMood: string;
    frustrationLevel: number;
    confidenceLevel: number;
  };
}

Deno.serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const { action, message, session_id, user_id, user_location, conversation_memory, emotional_state } = await req.json();

    switch (action) {
      case 'start_conversation':
        return await startAdvancedConversation(session_id, user_id, user_location);
      
      case 'send_message':
        return await processAdvancedMessage(message, conversation_memory, emotional_state);
      
      case 'location_updated':
        return await handleLocationUpdate(message.conversation_id, user_location);
      
      case 'generate_diagnostic_report':
        return await generateDiagnosticReport(message.conversation_id, conversation_memory);
      
      case 'end_conversation':
        return await endAdvancedConversation(message.conversation_id, conversation_memory, message.satisfaction_score);
      
      default:
        throw new Error('Action non reconnue');
    }

  } catch (error) {
    console.error('Erreur chatbot avanc√©:', error);
    return new Response(JSON.stringify({ 
      error: 'Une erreur est survenue lors du traitement de votre message.',
      fallback_response: "D√©sol√© pour le probl√®me technique ! Je suis toujours l√† pour vous aider. üòä"
    }), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' }
    });
  }
});

async function startAdvancedConversation(sessionId: string, userId?: string, userLocation?: [number, number]) {
  // Cr√©er une nouvelle conversation
  const { data: conversation, error } = await supabase
    .from('chatbot_conversations')
    .insert({
      session_id: sessionId,
      user_id: userId || null,
      user_type: userId ? 'authenticated' : 'anonymous',
      status: 'active',
      context: {
        user_location: userLocation,
        conversation_start: new Date().toISOString(),
        advanced_features: true
      }
    })
    .select()
    .single();

  if (error) throw error;

  // Incr√©menter les m√©triques
  await supabase.rpc('increment_chatbot_metric', { 
    metric_name: 'advanced_conversations_started' 
  });

  // Message de bienvenue adaptatif selon l'heure et la localisation
  const hour = new Date().getHours();
  let greeting = 'Bonjour';
  if (hour >= 18) greeting = 'Bonsoir';
  else if (hour >= 12) greeting = 'Bon apr√®s-midi';

  let locationContext = '';
  if (userLocation) {
    locationContext = ' Je vois que vous √™tes connect√© avec votre localisation, parfait pour vous trouver un r√©parateur proche !';
  }

  const welcomeMessage = `${greeting} ! üëã Je suis Ben, votre assistant de r√©paration nouvelle g√©n√©ration ! 

Je suis l√† pour vous offrir une exp√©rience personnalis√©e et vous aider √† diagnostiquer pr√©cis√©ment votre probl√®me de smartphone.${locationContext}

üî¨ **Ce que je peux faire pour vous :**
‚Ä¢ Diagnostic intelligent √©tape par √©tape
‚Ä¢ Estimation pr√©cise des co√ªts de r√©paration  
‚Ä¢ Recommandation des meilleurs r√©parateurs pr√®s de chez vous
‚Ä¢ Suivi personnalis√© de votre demande

Comment puis-je vous aider aujourd'hui ? üòä`;

  return new Response(JSON.stringify({ 
    conversation_id: conversation.id,
    message: welcomeMessage,
    suggestions: [
      "üîç Diagnostic de mon probl√®me",
      "üì± Mon √©cran est cass√©",
      "üîã Probl√®me de batterie",
      "üìç Trouver un r√©parateur pr√®s de moi"
    ],
    actions: [
      { type: 'button', label: 'Commencer le diagnostic', action: 'start_diagnostic' },
      { type: 'button', label: 'Urgence (r√©paration imm√©diate)', action: 'urgent_repair' }
    ]
  }), {
    headers: { ...corsHeaders, 'Content-Type': 'application/json' }
  });
}

async function processAdvancedMessage(message: any, conversationMemory: ConversationMemory, emotionalState: any) {
  const { conversation_id, content, user_location } = message;

  // Sauvegarder le message utilisateur
  await supabase
    .from('chatbot_messages')
    .insert({
      conversation_id,
      sender_type: 'user',
      content,
      message_type: 'text'
    });

  // Analyser avec l'IA avanc√©e
  const aiResponse = await analyzeWithAdvancedAI(
    content, 
    conversation_id, 
    conversationMemory, 
    emotionalState,
    user_location
  );

  // Sauvegarder la r√©ponse du bot
  await supabase
    .from('chatbot_messages')
    .insert({
      conversation_id,
      sender_type: 'bot',
      content: aiResponse.content,
      message_type: 'text',
      confidence_score: aiResponse.confidence,
      metadata: aiResponse.metadata
    });

  // Mettre √† jour le contexte de conversation
  await supabase
    .from('chatbot_conversations')
    .update({ 
      context: aiResponse.updated_context,
      updated_at: new Date().toISOString()
    })
    .eq('id', conversation_id);

  // Incr√©menter les m√©triques
  await supabase.rpc('increment_chatbot_metric', { 
    metric_name: 'advanced_messages_processed' 
  });

  return new Response(JSON.stringify({
    response: aiResponse.content,
    confidence: aiResponse.confidence,
    suggestions: aiResponse.suggestions,
    actions: aiResponse.actions,
    emotional_context: aiResponse.emotional_context,
    diagnostic_data: aiResponse.diagnostic_data,
    metadata: {
      ...aiResponse.metadata,
      complexity: aiResponse.complexity || 'medium'
    }
  }), {
    headers: { ...corsHeaders, 'Content-Type': 'application/json' }
  });
}

async function analyzeWithAdvancedAI(
  content: string, 
  conversationId: string, 
  conversationMemory: ConversationMemory,
  emotionalState: any,
  userLocation?: [number, number]
) {
  if (!openAIApiKey) {
    return await analyzeWithEnhancedRules(content, conversationId, conversationMemory);
  }

  try {
    // R√©cup√©rer l'historique de conversation
    const { data: messages } = await supabase
      .from('chatbot_messages')
      .select('*')
      .eq('conversation_id', conversationId)
      .order('created_at', { ascending: true })
      .limit(15);

    // Construire le contexte enrichi
    const conversationHistory = messages?.map((m, index) => 
      `${index + 1}. ${m.sender_type === 'user' ? 'Client' : 'Ben'}: ${m.content}`
    ).join('\n') || '';

    // Analyser les r√©parateurs proches si localisation disponible
    let nearbyRepairersContext = '';
    if (userLocation) {
      const { data: nearbyRepairers } = await supabase
        .from('repairers')
        .select('name, address, rating, specialties')
        .not('lat', 'is', null)
        .not('lng', 'is', null)
        .limit(5);
      
      if (nearbyRepairers && nearbyRepairers.length > 0) {
        nearbyRepairersContext = `\nüè™ R√âPARATEURS PROCHES DISPONIBLES:\n${nearbyRepairers.map(r => 
          `- ${r.name} (${r.rating}/5) - ${r.address}`
        ).join('\n')}`;
      }
    }

    // Construire le prompt ultra-sophistiqu√©
    const advancedPrompt = `Tu es Ben, l'assistant IA ultra-intelligent de RepairConnect, sp√©cialis√© dans l'accompagnement personnalis√© pour la r√©paration de smartphones. Tu es √©quip√© d'une intelligence √©motionnelle avanc√©e et d'un moteur de diagnostic de pointe.

üß† **PROFIL UTILISATEUR ANALYS√â:**
- Style de communication: ${conversationMemory.userProfile.communicationStyle}
- Niveau d'urgence: ${conversationMemory.userProfile.urgencyLevel}
- Appareils pr√©c√©dents: ${conversationMemory.userProfile.previousIssues?.join(', ') || 'Aucun historique'}
- Satisfaction moyenne: ${conversationMemory.userProfile.satisfactionHistory[conversationMemory.userProfile.satisfactionHistory.length - 1]}%

üìä **CONTEXTE √âMOTIONNEL ACTUEL:**
- √âmotion d√©tect√©e: ${emotionalState.currentEmotion}
- Niveau de frustration: ${conversationMemory.emotionalJourney.frustrationLevel}/10
- Confiance en la solution: ${conversationMemory.emotionalJourney.confidenceLevel}%
- Humeur conversation: ${conversationMemory.emotionalJourney.currentMood}

üî¨ **√âTAT DU DIAGNOSTIC:**
- √âtape actuelle: ${conversationMemory.conversationContext.diagnosisStage}
- Sympt√¥mes identifi√©s: ${conversationMemory.conversationContext.collectedSymptoms.join(', ') || 'Aucun'}
- Solutions sugg√©r√©es: ${conversationMemory.conversationContext.suggestedSolutions.join(', ') || 'Aucune'}

üìù **HISTORIQUE CONVERSATION:**
${conversationHistory}

üí¨ **MESSAGE UTILISATEUR ACTUEL:** "${content}"

${nearbyRepairersContext}

üéØ **INSTRUCTIONS COMPORTEMENTALES AVANC√âES:**

**Adaptation du style selon le profil:**
- Si 'formal': Vouvoyez, soyez professionnel mais chaleureux
- Si 'casual': Tutoyez, soyez d√©contract√© et amical  
- Si 'technical': Utilisez du vocabulaire technique appropri√©

**Gestion √©motionnelle intelligente:**
- Si frustration √©lev√©e (>6): Empathie imm√©diate + action concr√®te
- Si confiance faible (<40%): Rassurance + √©tapes claires
- Si urgence haute: Priorisez les solutions rapides
- Si satisfaction en baisse: Changez d'approche + proposez escalade

**Strat√©gie diagnostique:**
1. **Identification** ‚Üí Collectez sympt√¥mes pr√©cis avec questions cibl√©es
2. **Analyse** ‚Üí Croisez sympt√¥mes avec base de connaissances
3. **Estimation** ‚Üí Donnez co√ªt approximatif et temps de r√©paration
4. **Recommandation** ‚Üí Orientez vers le meilleur r√©parateur selon crit√®res

**Personnalisation des r√©ponses:**
- Variez expressions pour √©viter r√©p√©titions robotiques
- Int√©grez √©l√©ments du contexte personnel mentionn√©
- Adaptez niveau de d√©tail selon expertise per√ßue
- Utilisez √©mojis avec parcimonie mais pertinence

**Recommandations g√©ographiques:**
- Si localisation: Recommandez r√©parateurs sp√©cifiques avec justification
- Estimez temps de trajet et disponibilit√©
- Comparez 2-3 options avec avantages de chacune

R√©ponds avec un JSON strictement valide contenant:
{
  "content": "R√©ponse naturelle, empathique et personnalis√©e en fran√ßais",
  "confidence": 0.85,
  "complexity": "simple|medium|complex",
  "emotional_context": {
    "detected_emotion": "empathy|concern|excitement|professional|supportive",
    "response_tone": "caring|urgent|reassuring|enthusiastic|technical",
    "adaptation_made": "Description de l'adaptation au profil utilisateur"
  },
  "diagnostic_data": {
    "symptoms_detected": ["symptome1", "symptome2"],
    "diagnosis_stage": "nouvelle_√©tape",
    "estimated_cost": "50-120‚Ç¨",
    "urgency_level": "low|medium|high",
    "confidence_diagnosis": 0.75
  },
  "suggestions": ["Suggestion contextualis√©e 1", "Suggestion 2", "Suggestion 3"],
  "actions": [
    {"type": "button", "label": "Action claire", "action": "action_id"},
    {"type": "location", "label": "Partager ma position", "action": "request_location"}
  ],
  "updated_context": {
    "conversation_memory_updates": "Nouveaux √©l√©ments √† retenir",
    "next_recommended_step": "√âtape suivante sugg√©r√©e"
  },
  "reasoning": "Explication du raisonnement suivi pour cette r√©ponse"
}`;

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openAIApiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        messages: [
          { role: 'system', content: advancedPrompt },
          { role: 'user', content: content }
        ],
        temperature: 0.7,
        max_tokens: 800,
        presence_penalty: 0.2,
        frequency_penalty: 0.3
      }),
    });

    if (!response.ok) {
      throw new Error(`OpenAI API error: ${response.status}`);
    }

    const data = await response.json();
    const aiResponse = data.choices[0].message.content;
    
    try {
      const parsedResponse = JSON.parse(aiResponse);
      return {
        content: parsedResponse.content,
        confidence: parsedResponse.confidence || 0.8,
        complexity: parsedResponse.complexity || 'medium',
        suggestions: parsedResponse.suggestions || [],
        actions: parsedResponse.actions || [],
        emotional_context: parsedResponse.emotional_context,
        diagnostic_data: parsedResponse.diagnostic_data,
        updated_context: parsedResponse.updated_context,
        metadata: {
          ai_model: 'gpt-4o-mini-advanced',
          reasoning: parsedResponse.reasoning,
          category: parsedResponse.diagnostic_data?.diagnosis_stage || 'general'
        }
      };
    } catch (parseError) {
      console.error('JSON parsing error:', parseError, 'Raw response:', aiResponse);
      return await analyzeWithEnhancedRules(content, conversationId, conversationMemory);
    }

  } catch (error) {
    console.error('Erreur OpenAI avanc√©e:', error);
    return await analyzeWithEnhancedRules(content, conversationId, conversationMemory);
  }
}

async function analyzeWithEnhancedRules(content: string, conversationId: string, conversationMemory: ConversationMemory) {
  const userInput = content.toLowerCase().trim();
  
  // D√©tection avanc√©e des intentions
  const intentions = {
    screen_broken: {
      keywords: ['√©cran', 'cass√©', 'fissure', 'p√©t√©', 'vitre', 'noir'],
      response: "Je vois que votre √©cran a un probl√®me ! üì±üíî C'est effectivement l'une des pannes les plus courantes. Pour vous aider au mieux, j'ai besoin de quelques pr√©cisions :",
      questions: [
        "L'√©cran tactile fonctionne-t-il encore ?",
        "Voyez-vous des couleurs anormales ou des lignes ?",
        "L'√©cran s'allume-t-il toujours ?"
      ],
      estimated_cost: "80-200‚Ç¨",
      urgency: "medium"
    },
    battery_issue: {
      keywords: ['batterie', 'autonomie', 'charge', 'd√©charge', 'pourcentage'],
      response: "Probl√®me de batterie d√©tect√© ! üîã C'est tr√®s fr√©quent apr√®s 2-3 ans d'utilisation. Laissez-moi vous aider √† identifier la cause exacte :",
      questions: [
        "Depuis quand durez-vous remarqu√© ce probl√®me ?",
        "Le t√©l√©phone chauffe-t-il pendant la charge ?",
        "L'autonomie s'est-elle d√©grad√©e progressivement ?"
      ],
      estimated_cost: "50-90‚Ç¨",
      urgency: "medium"
    },
    water_damage: {
      keywords: ['eau', 'mouill√©', 'tomb√©', 'liquide', 'humidit√©'],
      response: "‚ö†Ô∏è D√©g√¢t des eaux d√©tect√© ! C'est une urgence ! Il faut agir rapidement pour limiter les dommages :",
      questions: [
        "Le t√©l√©phone √©tait-il compl√®tement immerg√© ?",
        "Combien de temps est-il rest√© en contact avec le liquide ?",
        "L'avez-vous √©teint imm√©diatement ?"
      ],
      estimated_cost: "100-300‚Ç¨",
      urgency: "high"
    }
  };

  // Analyser l'intention
  let bestMatch = null;
  let bestScore = 0;

  for (const [intention, data] of Object.entries(intentions)) {
    const matches = data.keywords.filter(keyword => userInput.includes(keyword)).length;
    const score = matches / data.keywords.length;
    
    if (score > bestScore && score > 0.3) {
      bestMatch = { intention, ...data, score };
    }
  }

  if (bestMatch) {
    return {
      content: `${bestMatch.response}\n\n${bestMatch.questions.map((q, i) => `${i + 1}. ${q}`).join('\n')}`,
      confidence: bestMatch.score,
      complexity: 'medium',
      suggestions: bestMatch.questions.slice(0, 3),
      actions: [
        { type: 'button', label: 'Voir les r√©parateurs', action: 'show_repairers' },
        { type: 'button', label: 'Estimation d√©taill√©e', action: 'detailed_quote' }
      ],
      emotional_context: {
        detected_emotion: bestMatch.urgency === 'high' ? 'concern' : 'supportive',
        response_tone: bestMatch.urgency === 'high' ? 'urgent' : 'caring'
      },
      diagnostic_data: {
        symptoms_detected: [bestMatch.intention],
        estimated_cost: bestMatch.estimated_cost,
        urgency_level: bestMatch.urgency,
        confidence_diagnosis: bestMatch.score
      },
      metadata: {
        ai_model: 'enhanced_rules',
        category: 'diagnostic'
      },
      updated_context: {}
    };
  }

  // R√©ponse g√©n√©rique enrichie
  return {
    content: "Je suis l√† pour vous aider ! üòä Pour vous proposer le meilleur service, pouvez-vous me d√©crire pr√©cis√©ment le probl√®me que vous rencontrez avec votre smartphone ?",
    confidence: 0.6,
    complexity: 'simple',
    suggestions: [
      "Mon √©cran est endommag√©",
      "Probl√®me de batterie ou charge", 
      "Mon t√©l√©phone ne s'allume plus",
      "Autre probl√®me"
    ],
    actions: [
      { type: 'button', label: 'Diagnostic guid√©', action: 'guided_diagnostic' }
    ],
    emotional_context: {
      detected_emotion: 'supportive',
      response_tone: 'encouraging'
    },
    diagnostic_data: {
      symptoms_detected: [],
      diagnosis_stage: 'problem_identification',
      urgency_level: 'medium'
    },
    metadata: {
      ai_model: 'enhanced_rules_fallback',
      category: 'general'
    },
    updated_context: {}
  };
}

async function handleLocationUpdate(conversationId: string, userLocation: [number, number]) {
  // Mettre √† jour le contexte avec la localisation
  await supabase
    .from('chatbot_conversations')
    .update({ 
      context: { user_location: userLocation, location_updated_at: new Date().toISOString() }
    })
    .eq('id', conversationId);

  return new Response(JSON.stringify({
    success: true,
    message: "Parfait ! J'ai bien re√ßu votre localisation. Je peux maintenant vous recommander les meilleurs r√©parateurs pr√®s de chez vous ! üìç"
  }), {
    headers: { ...corsHeaders, 'Content-Type': 'application/json' }
  });
}

async function generateDiagnosticReport(conversationId: string, conversationMemory: ConversationMemory) {
  const symptoms = conversationMemory.conversationContext.collectedSymptoms;
  
  const report = {
    summary: `Diagnostic bas√© sur ${symptoms.length} sympt√¥me(s) identifi√©(s)`,
    symptoms: symptoms,
    recommendations: [
      "Consultation d'un r√©parateur agr√©√© recommand√©e",
      "Obtenir un devis d√©taill√© avant r√©paration",
      "Sauvegarder vos donn√©es importantes"
    ],
    estimated_timeline: "1-3 jours ouvr√©s",
    confidence_level: conversationMemory.emotionalJourney.confidenceLevel
  };

  return new Response(JSON.stringify({ report }), {
    headers: { ...corsHeaders, 'Content-Type': 'application/json' }
  });
}

async function endAdvancedConversation(conversationId: string, conversationMemory: ConversationMemory, satisfactionScore: number) {
  await supabase
    .from('chatbot_conversations')
    .update({ 
      status: 'completed',
      completed_at: new Date().toISOString(),
      satisfaction_score: satisfactionScore,
      context: { 
        final_memory: conversationMemory,
        completion_reason: 'user_ended'
      }
    })
    .eq('id', conversationId);

  return new Response(JSON.stringify({
    success: true,
    message: "Merci d'avoir utilis√© notre assistant ! N'h√©sitez pas √† revenir si vous avez d'autres questions. üòä"
  }), {
    headers: { ...corsHeaders, 'Content-Type': 'application/json' }
  });
}