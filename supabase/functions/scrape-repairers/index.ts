
import { serve } from "https://deno.land/std@0.168.0/http/server.ts"
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'
import { corsHeaders, userAgents } from './constants.ts'
import { classifyRepairer } from './classifier.ts'
import { getDepartmentCoordinates } from './geography.ts'
import { getMassiveRepairersData } from './data-sources.ts'
import { randomDelay, sleep } from './utils.ts'

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders })
  }

  try {
    const supabase = createClient(
      Deno.env.get('SUPABASE_URL') ?? '',
      Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? '',
    )

    const { source, testMode = false, departmentCode = null } = await req.json()
    
    console.log(`üöÄ D√©marrage du scraping ${testMode ? 'TEST' : 'MASSIF'} pour source: ${source}${departmentCode ? ` - D√©partement: ${departmentCode}` : ''}`)

    // Cr√©er un log de scraping
    const { data: logData, error: logError } = await supabase
      .from('scraping_logs')
      .insert({
        source,
        status: 'running',
        started_at: new Date().toISOString()
      })
      .select()
      .single()

    if (logError) {
      console.error('‚ùå Erreur cr√©ation log:', logError)
      throw logError
    }

    console.log(`‚úÖ Log cr√©√© avec succ√®s: ${logData.id}`)

    const scrapedData = getMassiveRepairersData(source, testMode, departmentCode)
    let itemsAdded = 0
    let itemsUpdated = 0

    console.log(`üìä Traitement de ${scrapedData.length} entreprises${departmentCode ? ` pour le d√©partement ${departmentCode}` : ''}...`)

    for (const [index, data] of scrapedData.entries()) {
      // Anti-blocage : d√©lai al√©atoire entre chaque traitement
      if (index > 0) {
        await sleep(randomDelay())
      }

      console.log(`üîÑ Analyse ${index + 1}/${scrapedData.length}: ${data.name}`)
      
      // Classification par mots-cl√©s
      const analysis = classifyRepairer(data)
      
      console.log(`üìä R√©sultat ${data.name}:`, {
        is_repairer: analysis.is_repairer,
        confidence: analysis.confidence
      })
      
      if (analysis.is_repairer && analysis.confidence > 0.5) {
        console.log(`‚úÖ R√©parateur identifi√©: ${data.name}`)
        
        // V√©rifier si le r√©parateur existe d√©j√† (par nom + ville pour √©viter doublons)
        const { data: existingRepairer } = await supabase
          .from('repairers')
          .select('id')
          .eq('name', data.name)
          .eq('city', data.city)
          .maybeSingle()

        // Coordonn√©es GPS bas√©es sur le d√©partement ou la ville
        const departmentFromPostal = data.postal_code.substring(0, 2)
        const coords = getDepartmentCoordinates(departmentFromPostal)
        const now = new Date().toISOString()

        const repairerData = {
          name: data.name,
          address: data.address,
          city: data.city,
          postal_code: data.postal_code,
          department: coords.name,
          region: coords.region,
          phone: data.phone,
          email: data.email,
          website: data.website,
          lat: coords.lat + (Math.random() - 0.5) * 0.01, // Petite variation
          lng: coords.lng + (Math.random() - 0.5) * 0.01,
          services: analysis.services,
          specialties: analysis.specialties,
          price_range: analysis.price_range,
          source,
          is_open: analysis.is_open,
          scraped_at: now,
          updated_at: now
        }

        if (existingRepairer) {
          // Mettre √† jour
          const { error: updateError } = await supabase
            .from('repairers')
            .update(repairerData)
            .eq('id', existingRepairer.id)

          if (!updateError) {
            itemsUpdated++
            console.log(`üîÑ R√©parateur mis √† jour: ${data.name}`)
          } else {
            console.error('‚ùå Erreur mise √† jour:', updateError)
          }
        } else {
          // Cr√©er nouveau
          const { error: insertError } = await supabase
            .from('repairers')
            .insert(repairerData)

          if (!insertError) {
            itemsAdded++
            console.log(`‚ûï Nouveau r√©parateur ajout√©: ${data.name}`)
          } else {
            console.error('‚ùå Erreur insertion:', insertError)
          }
        }
      } else {
        console.log(`‚ùå Non-r√©parateur: ${data.name} (confiance: ${analysis.confidence})`)
      }
    }

    // Mettre √† jour le log de succ√®s
    await supabase
      .from('scraping_logs')
      .update({
        status: 'completed',
        items_scraped: scrapedData.length,
        items_added: itemsAdded,
        items_updated: itemsUpdated,
        completed_at: new Date().toISOString()
      })
      .eq('id', logData.id)

    console.log(`üéâ Scraping ${testMode ? 'TEST' : 'MASSIF'} termin√©: ${itemsAdded} ajout√©s, ${itemsUpdated} mis √† jour sur ${scrapedData.length} trait√©s`)

    return new Response(
      JSON.stringify({ 
        success: true, 
        message: `Scraping ${testMode ? 'TEST' : 'MASSIF'} ${source} termin√© avec succ√®s`,
        items_added: itemsAdded,
        items_updated: itemsUpdated,
        items_scraped: scrapedData.length,
        department: departmentCode,
        classification_method: 'Mots-cl√©s + G√©olocalisation automatique'
      }),
      { 
        headers: { 
          ...corsHeaders, 
          'Content-Type': 'application/json' 
        } 
      }
    )

  } catch (error) {
    console.error('üí• Erreur dans scrape-repairers:', error)
    
    return new Response(
      JSON.stringify({ 
        error: error.message,
        details: 'Consultez les logs pour plus de d√©tails'
      }),
      { 
        headers: { 
          ...corsHeaders, 
          'Content-Type': 'application/json' 
        }, 
        status: 500 
      }
    )
  }
})
