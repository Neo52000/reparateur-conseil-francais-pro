
import { useState, useEffect, useRef } from 'react';
import { supabase } from '@/integrations/supabase/client';
import { useToast } from '@/hooks/use-toast';
import { ScrapingLog } from './useScrapingStatusTypes';

export const useScrapingLogs = (autoRefreshEnabled: boolean) => {
  const { toast } = useToast();
  const [logs, setLogs] = useState<ScrapingLog[]>([]);
  const [loading, setLoading] = useState(true);
  const [isScrapingRunning, setIsScrapingRunning] = useState(false);
  const channelRef = useRef<any>(null);

  const testSupabaseConnection = async () => {
    try {
      console.log('ðŸ” Test de connexion Supabase...');
      
      const { data: authData, error: authError } = await supabase.auth.getSession();
      console.log('ðŸ” Session auth:', { 
        hasSession: !!authData.session, 
        error: authError?.message 
      });

      const { data: testData, error: testError } = await supabase
        .from('profiles')
        .select('count')
        .limit(1);

      if (testError) {
        console.error('âŒ Erreur de test DB:', testError);
        throw testError;
      }

      console.log('âœ… Connexion Supabase OK');
      return true;
    } catch (error) {
      console.error('ðŸ’¥ Erreur de connexion Supabase:', error);
      toast({
        title: "Erreur de connexion Supabase",
        description: "Impossible de se connecter Ã  la base de donnÃ©es. VÃ©rifiez votre connexion.",
        variant: "destructive"
      });
      return false;
    }
  };

  const fetchLogs = async () => {
    try {
      console.log('ðŸ”„ Tentative de rÃ©cupÃ©ration des logs de scraping...');
      
      const connectionOk = await testSupabaseConnection();
      if (!connectionOk) {
        setLogs([]);
        setIsScrapingRunning(false);
        setLoading(false);
        return;
      }

      const { data, error } = await supabase
        .from('scraping_logs')
        .select('*')
        .order('started_at', { ascending: false })
        .limit(10);

      if (error) {
        console.error('âŒ Erreur lors de la rÃ©cupÃ©ration des logs:', error);
        toast({
          title: "Erreur de rÃ©cupÃ©ration des logs",
          description: `Impossible de rÃ©cupÃ©rer les logs: ${error.message}`,
          variant: "destructive"
        });
        throw error;
      }

      console.log('âœ… Logs rÃ©cupÃ©rÃ©s avec succÃ¨s:', data?.length || 0, 'entrÃ©es');

      const typedLogs: ScrapingLog[] = (data || []).map(log => ({
        ...log,
        status: log.status as 'running' | 'completed' | 'failed'
      }));

      // AmÃ©liorer la dÃ©tection du scraping en cours
      const runningLogs = typedLogs.filter(log => log.status === 'running');
      
      // Ã‰galement vÃ©rifier les logs rÃ©cents (moins de 2 minutes) sans "completed_at"
      const recentLogs = typedLogs.filter(log => {
        if (log.status === 'running') return true;
        
        const logTime = new Date(log.started_at).getTime();
        const now = Date.now();
        const twoMinutesAgo = now - (2 * 60 * 1000);
        
        return logTime > twoMinutesAgo && !log.completed_at && log.status !== 'failed';
      });
      
      const hasRunningScrap = runningLogs.length > 0 || recentLogs.length > 0;
      
      console.log('ðŸŽ¯ ANALYSE DÃ‰TAILLÃ‰E DU STATUT SCRAPING:', {
        totalLogs: typedLogs.length,
        runningLogs: runningLogs.length,
        recentLogs: recentLogs.length,
        hasRunningScrap,
        runningDetails: runningLogs.map(log => ({
          id: log.id,
          source: log.source,
          status: log.status,
          started_at: log.started_at,
          completed_at: log.completed_at
        }))
      });

      setLogs(typedLogs);
      setIsScrapingRunning(hasRunningScrap);
      
      if (hasRunningScrap) {
        console.log('ðŸ”´ SCRAPING EN COURS DÃ‰TECTÃ‰ - Le bouton STOP devrait Ãªtre visible!');
      } else {
        console.log('âšª Aucun scraping en cours - Bouton STOP masquÃ©');
      }
      
    } catch (error) {
      console.error('ðŸ’¥ Erreur complÃ¨te fetchLogs:', error);
      setLogs([]);
      setIsScrapingRunning(false);
    } finally {
      setLoading(false);
    }
  };

  // VÃ©rification plus frÃ©quente du statut
  useEffect(() => {
    const interval = setInterval(() => {
      console.log('â° VÃ©rification pÃ©riodique du statut de scraping...');
      fetchLogs();
    }, 3000); // RÃ©duit Ã  3 secondes pour une meilleure rÃ©activitÃ©

    return () => clearInterval(interval);
  }, []);

  useEffect(() => {
    if (channelRef.current) {
      console.log('ðŸ§¹ Nettoyage de la subscription existante');
      supabase.removeChannel(channelRef.current);
      channelRef.current = null;
    }

    fetchLogs();

    if (!channelRef.current && autoRefreshEnabled) {
      console.log('ðŸ“¡ CrÃ©ation de la subscription realtime');
      
      channelRef.current = supabase
        .channel(`scraping_logs_${Date.now()}`)
        .on('postgres_changes', {
          event: '*',
          schema: 'public',
          table: 'scraping_logs'
        }, (payload) => {
          console.log('ðŸ”„ Changement temps rÃ©el dÃ©tectÃ©:', payload);
          fetchLogs();
        });

      channelRef.current.subscribe((status: string) => {
        console.log('ðŸ“¡ Statut subscription:', status);
        if (status === 'SUBSCRIBED') {
          console.log('âœ… Subscription realtime active');
        } else if (status === 'CHANNEL_ERROR') {
          console.error('âŒ Erreur de subscription realtime');
          toast({
            title: "Erreur temps rÃ©el",
            description: "La mise Ã  jour automatique ne fonctionne pas.",
            variant: "destructive"
          });
        }
      });
    }

    return () => {
      console.log('ðŸ§¹ Nettoyage de la subscription lors du dÃ©montage');
      if (channelRef.current) {
        supabase.removeChannel(channelRef.current);
        channelRef.current = null;
      }
    };
  }, [autoRefreshEnabled]);

  return {
    logs,
    loading,
    isScrapingRunning,
    refetch: fetchLogs
  };
};
