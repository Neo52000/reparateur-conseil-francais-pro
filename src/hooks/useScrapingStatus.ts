
import { useState, useEffect, useRef } from 'react';
import { supabase } from '@/integrations/supabase/client';
import { useToast } from '@/hooks/use-toast';

export interface ScrapingLog {
  id: string;
  source: string;
  status: 'running' | 'completed' | 'failed';
  items_scraped: number;
  items_added: number;
  items_updated: number;
  items_pappers_verified?: number;
  items_pappers_rejected?: number;
  pappers_api_calls?: number;
  error_message?: string;
  started_at: string;
  completed_at?: string;
}

export const useScrapingStatus = () => {
  const [logs, setLogs] = useState<ScrapingLog[]>([]);
  const [loading, setLoading] = useState(true);
  const [isScrapingRunning, setIsScrapingRunning] = useState(false);
  const [autoRefreshEnabled, setAutoRefreshEnabled] = useState(true);
  const { toast } = useToast();
  const channelRef = useRef<any>(null);

  const testSupabaseConnection = async () => {
    try {
      console.log('ðŸ” Test de connexion Supabase...');
      
      const { data: authData, error: authError } = await supabase.auth.getSession();
      console.log('ðŸ” Session auth:', { 
        hasSession: !!authData.session, 
        error: authError?.message 
      });

      const { data: testData, error: testError } = await supabase
        .from('profiles')
        .select('count')
        .limit(1);

      if (testError) {
        console.error('âŒ Erreur de test DB:', testError);
        throw testError;
      }

      console.log('âœ… Connexion Supabase OK');
      return true;
    } catch (error) {
      console.error('ðŸ’¥ Erreur de connexion Supabase:', error);
      toast({
        title: "Erreur de connexion Supabase",
        description: "Impossible de se connecter Ã  la base de donnÃ©es. VÃ©rifiez votre connexion.",
        variant: "destructive"
      });
      return false;
    }
  };

  const fetchLogs = async () => {
    try {
      console.log('ðŸ”„ Tentative de rÃ©cupÃ©ration des logs de scraping...');
      
      const connectionOk = await testSupabaseConnection();
      if (!connectionOk) {
        setLogs([]);
        setIsScrapingRunning(false);
        setLoading(false);
        return;
      }

      const { data, error } = await supabase
        .from('scraping_logs')
        .select('*')
        .order('started_at', { ascending: false })
        .limit(10);

      if (error) {
        console.error('âŒ Erreur lors de la rÃ©cupÃ©ration des logs:', error);
        console.error('ðŸ“ DÃ©tails de l\'erreur:', {
          message: error.message,
          details: error.details,
          hint: error.hint,
          code: error.code
        });
        
        toast({
          title: "Erreur de rÃ©cupÃ©ration des logs",
          description: `Impossible de rÃ©cupÃ©rer les logs: ${error.message}`,
          variant: "destructive"
        });
        throw error;
      }

      console.log('âœ… Logs rÃ©cupÃ©rÃ©s avec succÃ¨s:', data?.length || 0, 'entrÃ©es');

      const typedLogs: ScrapingLog[] = (data || []).map(log => ({
        ...log,
        status: log.status as 'running' | 'completed' | 'failed'
      }));

      setLogs(typedLogs);
      setIsScrapingRunning(typedLogs.some(log => log.status === 'running') || false);
    } catch (error) {
      console.error('ðŸ’¥ Erreur complÃ¨te fetchLogs:', error);
      setLogs([]);
      setIsScrapingRunning(false);
    } finally {
      setLoading(false);
    }
  };

  const startScraping = async (source: string, testMode: boolean = false, departmentCode: string | null = null) => {
    try {
      console.log(`ðŸš€ DÃ©marrage du scraping ${testMode ? 'TEST' : 'MASSIF'} pour: ${source}${departmentCode ? ` - DÃ©partement: ${departmentCode}` : ''}`);
      
      const connectionOk = await testSupabaseConnection();
      if (!connectionOk) {
        throw new Error('Connexion Supabase dÃ©faillante');
      }

      const { data, error } = await supabase.functions.invoke('scrape-repairers', {
        body: { 
          source, 
          testMode,
          departmentCode 
        }
      });

      if (error) {
        console.error('âŒ Erreur Edge Function:', error);
        throw error;
      }

      console.log('âœ… RÃ©ponse Edge Function:', data);

      const scrapingType = testMode ? "ðŸ§ª Test" : "ðŸš€ Scraping MASSIF";
      const locationText = departmentCode ? ` (DÃ©partement ${departmentCode})` : " (Toute la France)";

      toast({
        title: `${scrapingType} dÃ©marrÃ©`,
        description: `${scrapingType} de ${source}${locationText} lancÃ©. ${data?.classification_method ? `MÃ©thode: ${data.classification_method}` : ''}`,
      });

      setTimeout(fetchLogs, 2000);
      
      return data;
    } catch (error) {
      console.error('ðŸ’¥ Erreur start scraping:', error);
      
      toast({
        title: "âŒ Erreur de scraping",
        description: error.message || "Impossible de dÃ©marrer le scraping. VÃ©rifiez les logs.",
        variant: "destructive"
      });
      
      throw error;
    }
  };

  const stopScraping = async () => {
    try {
      console.log('ðŸ›‘ Demande d\'arrÃªt du scraping...');
      
      const { data, error } = await supabase.functions.invoke('stop-scraping');

      if (error) {
        console.error('âŒ Erreur lors de l\'arrÃªt:', error);
        throw error;
      }

      console.log('âœ… RÃ©ponse arrÃªt scraping:', data);

      toast({
        title: "ðŸ›‘ Scraping arrÃªtÃ©",
        description: data?.message || "Le scraping a Ã©tÃ© arrÃªtÃ© avec succÃ¨s",
      });

      setTimeout(fetchLogs, 1000);
      
      return data;
    } catch (error) {
      console.error('ðŸ’¥ Erreur stop scraping:', error);
      
      toast({
        title: "âŒ Erreur d'arrÃªt",
        description: error.message || "Impossible d'arrÃªter le scraping",
        variant: "destructive"
      });
      
      throw error;
    }
  };

  useEffect(() => {
    if (channelRef.current) {
      console.log('ðŸ§¹ Nettoyage de la subscription existante');
      supabase.removeChannel(channelRef.current);
      channelRef.current = null;
    }

    fetchLogs();

    if (!channelRef.current && autoRefreshEnabled) {
      console.log('ðŸ“¡ CrÃ©ation de la subscription realtime');
      
      channelRef.current = supabase
        .channel(`scraping_logs_${Date.now()}`)
        .on('postgres_changes', {
          event: '*',
          schema: 'public',
          table: 'scraping_logs'
        }, (payload) => {
          console.log('ðŸ”„ Changement temps rÃ©el dÃ©tectÃ©:', payload);
          fetchLogs();
        });

      channelRef.current.subscribe((status: string) => {
        console.log('ðŸ“¡ Statut subscription:', status);
        if (status === 'SUBSCRIBED') {
          console.log('âœ… Subscription realtime active');
        } else if (status === 'CHANNEL_ERROR') {
          console.error('âŒ Erreur de subscription realtime');
          toast({
            title: "Erreur temps rÃ©el",
            description: "La mise Ã  jour automatique ne fonctionne pas.",
            variant: "destructive"
          });
        } else if (status === 'CLOSED') {
          console.warn('âš ï¸ Subscription fermÃ©e');
        }
      });
    }

    return () => {
      console.log('ðŸ§¹ Nettoyage de la subscription lors du dÃ©montage');
      if (channelRef.current) {
        supabase.removeChannel(channelRef.current);
        channelRef.current = null;
      }
    };
  }, [autoRefreshEnabled]);

  return {
    logs,
    loading,
    isScrapingRunning,
    autoRefreshEnabled,
    setAutoRefreshEnabled,
    startScraping,
    stopScraping,
    refetch: fetchLogs
  };
};
